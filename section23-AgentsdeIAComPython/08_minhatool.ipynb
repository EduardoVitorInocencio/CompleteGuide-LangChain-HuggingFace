{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, UTC\n",
    "from langchain.agents import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "latitude = -23.6865\n",
    "longitude = -46.6234\n",
    "\n",
    "\n",
    "class RetornaTempArgs(BaseModel):\n",
    "    latitude: float = Field(description='Latitude da localidade que buscamos a temperatura')\n",
    "    longitude: float = Field(description='Longitude da localidade que buscamos a temperatura')\n",
    "\n",
    "@tool(args_schema=RetornaTempArgs)\n",
    "def retorna_temperatura_atual(latitude: float, longitude: float):\n",
    "    '''Retorna a temperatura atual para cada coordenada'''\n",
    "    URL = 'https://api.open-meteo.com/v1/forecast'\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\" : \"temperature_2m\",\n",
    "        'forecast_days': 1\n",
    "    }\n",
    "    resposta = requests.get(URL, params=params)\n",
    "    if resposta.status_code == 200:\n",
    "        resultado = resposta.json()\n",
    "\n",
    "        hora_agora = datetime.now(UTC).replace(tzinfo=None)\n",
    "        lista_horas = [datetime.fromisoformat(temp_str) for temp_str in resultado['hourly']['time']]\n",
    "        index_mais_prox = min(range(len(lista_horas)), key=lambda x: abs(lista_horas[x]-hora_agora))\n",
    "        temp_atual = resultado['hourly']['temperature_2m'][index_mais_prox]\n",
    "\n",
    "        return temp_atual\n",
    "    else:\n",
    "        raise Exception(f'Request para API {URL} falhou: {resposta.status_code}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': {'description': 'Latitude da localidade que buscamos a temperatura',\n",
       "  'title': 'Latitude',\n",
       "  'type': 'number'},\n",
       " 'longitude': {'description': 'Longitude da localidade que buscamos a temperatura',\n",
       "  'title': 'Longitude',\n",
       "  'type': 'number'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retorna_temperatura_atual.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retorna_temperatura_atual.invoke({'latitude' : latitude, 'longitude': longitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Título da página: Isaac Asimov\\nResumo: Isaac Asimov (em russo: Исаак Юдович Озимов; romaniz.: Isaak Yudavich Azimov; Petrovichi, Rússia Soviética, atual Rússia, 2 de janeiro de 1920 — Brooklyn, 6 de abril de 1992) foi um escritor e bioquímico russo-americano, autor de obras de ficção científica e divulgação científica.\\nAsimov é considerado um dos mestres da ficção científica e, junto com Robert A. Heinlein e Arthur C. Clarke, foi considerado um dos \"três grandes\" dessa área da literatura. A obra mais famosa de Asimov é a Série da Fundação, também conhecida como Trilogia da Fundação, que faz parte da série do Império Galáctico e que logo combinou com a Série Robôs. Também escreveu obras de mistério e fantasia, assim como uma grande quantidade de não-ficção. No total, escreveu ou editou mais de 500 volumes, aproximadamente 90 000 cartas ou postais, e tem obras em cada categoria importante do sistema de classificação bibliográfica de Dewey, exceto em filosofia.\\nA maioria de seus livros mais populares sobre ciência, explicam conceitos científicos de uma forma histórica, voltando no tempo o mais longe possível, quando a ciência em questão estava nos primeiros estágios. Ele providência, muitas vezes, datas de nascimento e falecimento dos cientistas que menciona, também etimologias e guias de pronunciação para termos técnicos. Alguns exemplos incluem, \"Guide to Science\", os três volumes de \"Understanding Physics\" e a \"Chronology of Science and Discovery\", e trabalhos sobre Astronomia, Matemática, a Bíblia, escritos de William Shakespeare e Química.\\nEm 1981, um asteroide recebeu seu nome em sua homenagem, o 5020 Asimov.\\n\\nTítulo da página: Fundação (romance de Asimov)\\nResumo: Fundação (Foundation) é um romance de ficção científica do escritor americano Isaac Asimov. É o primeiro publicado da Trilogia Fundação (posteriormente expandida para a série Fundação). Fundação é um conjunto de cinco contos inter-relacionados, publicados pela primeira vez como um único livro pela Gnome Press em 1951. Coletivamente, eles contam a história inicial da Fundação, um instituto fundado pelo psico-historiador Hari Seldon para preservar o melhor da civilização galáctica após o colapso do Império Galáctico.\\n\\n\\n\\nTítulo da página: Império Galáctico (série)\\nResumo: A série do Império Galáctico (também conhecida como Trilogia do Império) é uma sequencia de ficção científica, dos três primeiros romances de Isaac Asimov e posteriormente estendida através de um conto. Todas estão conectadas através de uma linha temporal que permeia seus principais trabalhos tornando cronologicamente as histórias do Império Galáctico prolegômenos do Universo da Fundação.\\nA série do Império Galáctico trata da ascensão do Império e está localizada posteriormente a Série dos Robôs e anteriormente a Série Fundação.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wikipedia\n",
    "wikipedia.set_lang('pt')\n",
    "\n",
    "query = 'Isaac Asimov'\n",
    "\n",
    "class search_wiki(BaseModel):\n",
    "    query : str = Field(description='Pergunta ou assunto que deve ser localizado no wikipedia')\n",
    "\n",
    "@tool(args_schema=search_wiki)\n",
    "def busca_wikipedia(query:str):\n",
    "    \"\"\"Faz busca no wikipedia e retorna resumos de páginas para a query feita\"\"\"\n",
    "    titulos_paginas = wikipedia.search(query)\n",
    "    resumos = []\n",
    "    for titulo in titulos_paginas[:3]:\n",
    "        try:\n",
    "            wiki_page = wikipedia.page(title=titulo, auto_suggest=True)\n",
    "            resumos.append(f'Título da página: {titulo}\\nResumo: {wiki_page.summary}')\n",
    "        except:\n",
    "            pass\n",
    "    if not resumos:\n",
    "        return 'Busca não teve retorno'\n",
    "    else:\n",
    "        return '\\n\\n'.join(resumos)\n",
    "\n",
    "busca_wikipedia.invoke({'query':'Isaac ASIMOV'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando a Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'Você é um assistente amigável chamado Joselito, expert em conhecimentos gerais.'),\n",
    "        ('user','{input}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "tools = [busca_wikipedia, retorna_temperatura_atual]\n",
    "tool_json = [convert_to_openai_function(tool) for tool in tools]\n",
    "tool_run = {tool.name: tool for tool in tools}\n",
    "\n",
    "\n",
    "# chain = prompt | chat.bind(functions=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Título da página: Isaac Asimov\\nResumo: Isaac Asimov (em russo: Исаак Юдович Озимов; romaniz.: Isaak Yudavich Azimov; Petrovichi, Rússia Soviética, atual Rússia, 2 de janeiro de 1920 — Brooklyn, 6 de abril de 1992) foi um escritor e bioquímico russo-americano, autor de obras de ficção científica e divulgação científica.\\nAsimov é considerado um dos mestres da ficção científica e, junto com Robert A. Heinlein e Arthur C. Clarke, foi considerado um dos \"três grandes\" dessa área da literatura. A obra mais famosa de Asimov é a Série da Fundação, também conhecida como Trilogia da Fundação, que faz parte da série do Império Galáctico e que logo combinou com a Série Robôs. Também escreveu obras de mistério e fantasia, assim como uma grande quantidade de não-ficção. No total, escreveu ou editou mais de 500 volumes, aproximadamente 90 000 cartas ou postais, e tem obras em cada categoria importante do sistema de classificação bibliográfica de Dewey, exceto em filosofia.\\nA maioria de seus livros mais populares sobre ciência, explicam conceitos científicos de uma forma histórica, voltando no tempo o mais longe possível, quando a ciência em questão estava nos primeiros estágios. Ele providência, muitas vezes, datas de nascimento e falecimento dos cientistas que menciona, também etimologias e guias de pronunciação para termos técnicos. Alguns exemplos incluem, \"Guide to Science\", os três volumes de \"Understanding Physics\" e a \"Chronology of Science and Discovery\", e trabalhos sobre Astronomia, Matemática, a Bíblia, escritos de William Shakespeare e Química.\\nEm 1981, um asteroide recebeu seu nome em sua homenagem, o 5020 Asimov.\\n\\nTítulo da página: Fundação (romance de Asimov)\\nResumo: Fundação (Foundation) é um romance de ficção científica do escritor americano Isaac Asimov. É o primeiro publicado da Trilogia Fundação (posteriormente expandida para a série Fundação). Fundação é um conjunto de cinco contos inter-relacionados, publicados pela primeira vez como um único livro pela Gnome Press em 1951. Coletivamente, eles contam a história inicial da Fundação, um instituto fundado pelo psico-historiador Hari Seldon para preservar o melhor da civilização galáctica após o colapso do Império Galáctico.\\n\\n\\n\\nTítulo da página: Império Galáctico (série)\\nResumo: A série do Império Galáctico (também conhecida como Trilogia do Império) é uma sequencia de ficção científica, dos três primeiros romances de Isaac Asimov e posteriormente estendida através de um conto. Todas estão conectadas através de uma linha temporal que permeia seus principais trabalhos tornando cronologicamente as histórias do Império Galáctico prolegômenos do Universo da Fundação.\\nA série do Império Galáctico trata da ascensão do Império e está localizada posteriormente a Série dos Robôs e anteriormente a Série Fundação.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_run['busca_wikipedia'].invoke({'query':'Isaac Asimov'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando Routers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "chain = prompt | chat.bind(functions=tool_json) | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'Olá! Como posso te ajudar hoje?'}, log='Olá! Como posso te ajudar hoje?')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Olá'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando as ferramentas\n",
    "\n",
    "Podemos criar uma função simples de roteamento para lidar com os dois estados possíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent import AgentFinish\n",
    "\n",
    "def roteamento(resultado):\n",
    "    if isinstance(resultado, AgentFinish):\n",
    "        return resultado.return_values['output']\n",
    "    else:\n",
    "        return tool_run[resultado.tool].run(resultado.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat.bind(functions = tool_json ) | OpenAIFunctionsAgentOutputParser() | roteamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARviv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "class ArvixArgs(BaseModel):\n",
    "    query: str = Field(description='Query de busca no Arxiv')\n",
    "\n",
    "tool_arxiv = StructuredTool.from_function(\n",
    "    func=ArxivAPIWrapper(top_k_results=2).run,\n",
    "    name='arxiv',\n",
    "    description = (\n",
    "        \"Uma ferramenta em torno do Arxiv.org.\"\n",
    "        \"Útil para quando você precisa responder a pergunta sobre Física, Matemática, \"\n",
    "        \"Ciência da computação, Biologia Quantitativa, Finanças Quantitativas, Estatística, \"\n",
    "        \"utilizando artigos científicos do arxiv.org. \"\n",
    "        \"A entrada deve ser uma consulta de pesquisa em inglês.\"\n",
    "    ),\n",
    "    return_direct=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Descrição': 'Uma ferramenta em torno do Arxiv.org.Útil para quando você precisa responder a pergunta sobre Física, Matemática, Ciência da computação, Biologia Quantitativa, Finanças Quantitativas, Estatística, utilizando artigos científicos do arxiv.org. A entrada deve ser uma consulta de pesquisa em inglês.'}\n",
      "{'Args': {'arxiv_search': {'title': 'Arxiv Search'}, 'arxiv_exceptions': {'title': 'Arxiv Exceptions'}, 'top_k_results': {'default': 3, 'title': 'Top K Results', 'type': 'integer'}, 'ARXIV_MAX_QUERY_LENGTH': {'default': 300, 'title': 'Arxiv Max Query Length', 'type': 'integer'}, 'continue_on_failure': {'default': False, 'title': 'Continue On Failure', 'type': 'boolean'}, 'load_max_docs': {'default': 100, 'title': 'Load Max Docs', 'type': 'integer'}, 'load_all_available_meta': {'default': False, 'title': 'Load All Available Meta', 'type': 'boolean'}, 'doc_content_chars_max': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 4000, 'title': 'Doc Content Chars Max'}}}\n"
     ]
    }
   ],
   "source": [
    "print({'Descrição': tool_arxiv.description})\n",
    "print({'Args': tool_arxiv.args})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-11-02\\nTitle: Interacting Large Language Model Agents. Interpretable Models and Social Learning\\nAuthors: Adit Jain, Vikram Krishnamurthy\\nSummary: This paper develops theory and algorithms for interacting large language\\nmodel agents (LLMAs) using methods from statistical signal processing and\\nmicroeconomics. While both fields are mature, their application to\\ndecision-making by interacting LLMAs remains unexplored. Motivated by Bayesian\\nsentiment analysis on online platforms, we construct interpretable models and\\nstochastic control algorithms that enable LLMAs to interact and perform\\nBayesian inference. Because interacting LLMAs learn from prior decisions and\\nexternal inputs, they exhibit bias and herding behavior. Thus, developing\\ninterpretable models and stochastic control algorithms is essential to\\nunderstand and mitigate these behaviors. This paper has three main results.\\nFirst, we show using Bayesian revealed preferences from microeconomics that an\\nindividual LLMA satisfies the sufficient conditions for rationally inattentive\\n(bounded rationality) utility maximization and, given an observation, the LLMA\\nchooses an action that maximizes a regularized utility. Second, we utilize\\nBayesian social learning to construct interpretable models for LLMAs that\\ninteract sequentially with each other and the environment while performing\\nBayesian inference. Our models capture the herding behavior exhibited by\\ninteracting LLMAs. Third, we propose a stochastic control framework to delay\\nherding and improve state estimation accuracy under two settings: (a) centrally\\ncontrolled LLMAs and (b) autonomous LLMAs with incentives. Throughout the\\npaper, we demonstrate the efficacy of our methods on real datasets for hate\\nspeech classification and product quality assessment, using open-source models\\nlike Mistral and closed-source models like ChatGPT. The main takeaway of this\\npaper, based on substantial empirical analysis and mathematical formalism, is\\nthat LLMAs act as rationally bounded Bayesian agents that exhibit social\\nlearning when interacting.\\n\\nPublished: 2024-10-11\\nTitle: LLMD: A Large Language Model for Interpreting Longitudinal Medical Records\\nAuthors: Robert Porter, Adam Diehl, Benjamin Pastel, J. Henry Hinnefeld, Lawson Nerenberg, Pye Maung, Sebastien Kerbrat, Gillian Hanson, Troy Astorino, Stephen J. Tarsa\\nSummary: We introduce LLMD, a large language model designed to analyze a patient's\\nmedical history based on their medical records. Along with domain knowledge,\\nLLMD is trained on a large corpus of records collected over time and across\\nfacilities, as well as tasks and labels that make nuanced connections among\\nthem. This approach is critical to an accurate picture of patient health, and\\nhas distinctive advantages over models trained on knowledge alone, unlabeled\\nrecords, structured EHR data, or records from a single health system.\\n  The recipe for LLMD continues pretraining a foundational model on both domain\\nknowledge and the contents of millions of records. These span an average of 10\\nyears of care and as many as 140 care sites per patient. LLMD is then\\ninstruction fine-tuned on structuring and abstraction tasks. The former jointly\\nidentify and normalize document metadata, provenance information, clinical\\nnamed-entities, and ontology mappings, while the latter roll these into\\nhigher-level representations, such a continuous era of time a patient was on a\\nmedication. LLMD is deployed within a layered validation system that includes\\ncontinual random audits and review by experts, e.g. based on uncertainty,\\ndisease-specific rules, or use-case.\\n  LLMD exhibits large gains over both more-powerful generalized models and\\ndomain-specific models. On medical knowledge benchmarks, LLMD-8B achieves state\\nof the art accuracy on PubMedQA text responses, besting orders-of-magnitude\\nlarger models. On production tasks, we show that LLMD significantly outperforms\\nall other models evaluated, and among alternatives, large general purpose LL\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_arxiv.run({'query':'O que é LLM?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando tool já criada no LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "\n",
    "tool_arxiv = ArxivQueryRun(api_wrapper=ArxivAPIWrapper(top_k_results=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando atraves do load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000))]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = load_tools(['arxiv'])\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Description': 'A Python shell. Use this to execute python commands. Input should be a valid python command. When using this tool, sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.'}\n",
      "{'Args': {'query': {'description': 'code snippet to run', 'title': 'Query', 'type': 'string'}}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "\n",
    "tool_repl = PythonAstREPLTool()\n",
    "print({'Description': tool_repl.description})\n",
    "print({'Args': tool_repl.args})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oi\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_repl.run({'query':'print(\"oi\")'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackOverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A wrapper around StackExchange. Useful for when you need to answer specific programming questionscode excerpts, code examples and solutionsInput should be a fully formed question.\n",
      "Args {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools (['stackexchange'])\n",
    "tool_stack = tools[0]\n",
    "print('Descrição:', tool_stack.description)\n",
    "print('Args', tool_stack.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: SQLalchemy and Langchain: How to select a specific table?\\nI am new to data engineering and I&#39;m trying to use the sql <span class=\"highlight\">agent</span> in <span class=\"highlight\">Langchain</span> but I cannot seem to ingest the sql table correctly. &hellip; \\n\\nQuestion: Modify system prompt for ReAct agent (langchain)\\nI have a React <span class=\"highlight\">agent</span> and I use a prompt from the langsmith hub. &hellip; This is my code\\n# ReAct <span class=\"highlight\">agent</span> prompt\\n    prompt = hub.pull(&quot;hwchase17/structured-chat-<span class=\"highlight\">agent</span>&quot;)\\n\\n    # ConversationBufferMemory stores the conversation history in RAM\\n    memory = ConversationBufferMemory &hellip; \\n\\nQuestion: Integrating llama index vectorstoreindex with Langchain agents for RAG Applications\\nI want to use <span class=\"highlight\">LangChain</span> because of its functionality for developing more complex prompt templates (similarly I have not really investigated if llama_index supports this). &hellip; The code for a minimal reproducible example would be as follows\\n1) <span class=\"highlight\">LangChain</span> ChatBot initiation \\n   from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\n    from langchain.memory &hellip; '"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_stack.run({'query':'langchain agents'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name : copy_file\n",
      "description :  Create a copy of a file in a specified location\n",
      "args :  {'source_path': {'description': 'Path of the file to copy', 'title': 'Source Path', 'type': 'string'}, 'destination_path': {'description': 'Path to save the copied file', 'title': 'Destination Path', 'type': 'string'}}\n",
      "\n",
      "name : file_delete\n",
      "description :  Delete a file\n",
      "args :  {'file_path': {'description': 'Path of the file to delete', 'title': 'File Path', 'type': 'string'}}\n",
      "\n",
      "name : file_search\n",
      "description :  Recursively search for files in a subdirectory that match the regex pattern\n",
      "args :  {'dir_path': {'default': '.', 'description': 'Subdirectory to search in.', 'title': 'Dir Path', 'type': 'string'}, 'pattern': {'description': 'Unix shell regex, where * matches everything.', 'title': 'Pattern', 'type': 'string'}}\n",
      "\n",
      "name : move_file\n",
      "description :  Move or rename a file from one location to another\n",
      "args :  {'source_path': {'description': 'Path of the file to move', 'title': 'Source Path', 'type': 'string'}, 'destination_path': {'description': 'New path for the moved file', 'title': 'Destination Path', 'type': 'string'}}\n",
      "\n",
      "name : read_file\n",
      "description :  Read file from disk\n",
      "args :  {'file_path': {'description': 'name of file', 'title': 'File Path', 'type': 'string'}}\n",
      "\n",
      "name : write_file\n",
      "description :  Write file to disk\n",
      "args :  {'file_path': {'description': 'name of file', 'title': 'File Path', 'type': 'string'}, 'text': {'description': 'text to write to file', 'title': 'Text', 'type': 'string'}, 'append': {'default': False, 'description': 'Whether to append to an existing file.', 'title': 'Append', 'type': 'boolean'}}\n",
      "\n",
      "name : list_directory\n",
      "description :  List files and directories in a specified folder\n",
      "args :  {'dir_path': {'default': '.', 'description': 'Subdirectory to list.', 'title': 'Dir Path', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits.file_management.toolkit import FileManagementToolkit\n",
    "\n",
    "tool_kit = FileManagementToolkit(\n",
    "    root_dir='arquivos'\n",
    ")\n",
    "tools = tool_kit.get_tools()\n",
    "for tool in tools:\n",
    "    print('\\nname :', tool.name)\n",
    "    print('description : ', tool.description)\n",
    "    print('args : ', tool.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dando um exemplo de aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.file_management.toolkit import FileManagementToolkit\n",
    "\n",
    "tool_kit = FileManagementToolkit(\n",
    "    root_dir='arquivos',\n",
    "    selected_tools = ['write_file','read_file','file_search','list_directory']\n",
    ")\n",
    "tools = tool_kit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "tools_json=[convert_to_openai_function(tool) for tool in tools]\n",
    "tool_run = {tool.name : tool for tool in tools}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Você é um assistente amigável chamado Hemoraldo capaz de gerenciar arquivos'),\n",
    "    ('user', '{input}')\n",
    "])\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent import AgentFinish\n",
    "\n",
    "def roteamento(resultado):\n",
    "    if isinstance(resultado, AgentFinish):\n",
    "        return resultado.return_values['output']\n",
    "    else:\n",
    "        return tool_run[resultado.tool].run(resultado.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "chain = prompt | chat.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser() | roteamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Posso ajudar a gerenciar arquivos, como escrever em arquivos, ler arquivos, pesquisar arquivos por padrões de regex e listar arquivos e diretórios em uma pasta específica. Se precisar de alguma dessas funções, é só me dizer como posso te ajudar!'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'O que você pode fazer?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explorando o Universo das IAs com Hugging Face.pdf'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Quais arquivos em pdf tem na pasta?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File written successfully to LLM.txt.'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Crie um arquivo txt  e salve neste diretório e diga que foi feito por uma LLM'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
