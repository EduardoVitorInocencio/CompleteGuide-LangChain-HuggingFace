{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG com LCEL\n",
    "\n",
    "Agora vamos para exemplos mais avançados de chains e como podemos reproduzí-las utilizando LCEL.\n",
    "\n",
    "Vamos começar mostrando como fazer o processos de RAG. Para isso, o processo de criação da vector store é exatamente igual ao que vimos no curso de Aplicações com IA com LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRIANDO CHUNKS - Carregando e particionando o documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [\n",
    "    \"arquivos\\Explorando o Universo das IAs com Hugging Face.pdf\"\n",
    "]\n",
    "\n",
    "pages = []\n",
    "\n",
    "for path in PATHS:\n",
    "    loader = PyPDFLoader(path)\n",
    "    pages.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap = 50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "documents = recur_split.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMBEDDINGS - Importando e instanciando o OpenAiEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edinocencio\\AppData\\Local\\Temp\\ipykernel_8548\\22710313.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORAGE - Amrazenando os dados em um VECTOR STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"mmr\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora na criação da chain é que temos uma mudança. Podemos definir nossa chain manualmente da seguinte forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import  StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from regex import template\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "template = \"\"\" Reponda as seguintes perguntas ao usuário utilizando apenas o contexto fornecido.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pergunta: {pergunta}\n",
    "\n",
    "\"\"\"\n",
    "template = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from certifi import contents\n",
    "from langchain_core.runnables import  RunnablePassthrough, RunnableParallel\n",
    "\n",
    "# RunnableParallel: Provavelmente é uma classe que permite executar múltiplos componentes em paralelo.\n",
    "# 'pergunta': Um componente que utiliza RunnablePassthrough, que parece ser uma classe que simplesmente passa os dados sem modificações.\n",
    "# 'context': Um componente que utiliza retriever, que deve ser um objeto ou função responsável por recuperar algum tipo de dados ou contexto.\n",
    "\n",
    "setup_and_retrievel = RunnableParallel(\n",
    "    {\n",
    "        'pergunta': RunnablePassthrough(),\n",
    "        'context': retriever\n",
    "     }\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
